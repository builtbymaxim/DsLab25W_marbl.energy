{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Weather Forecast Ingestion (Inference)\n",
    "\n",
    "**Project:** Electricity Price Forecasting\n",
    "**Stage:** Ingestion (Live Data)\n",
    "\n",
    "**Objective:**\n",
    "This notebook fetches live weather forecasts for the next 3 days. This data serves as the input (inference data) for the machine learning model to predict future electricity prices.\n",
    "\n",
    "**Data Source:**\n",
    "* **Provider:** WeatherAPI.com\n",
    "* **Method:** REST API\n",
    "* **Granularity:** Hourly\n",
    "\n",
    "**Methodology:**\n",
    "To match the \"Zonal Spatial Mean\" used in our training data (ERA5), we do not rely on a single city. Instead, we:\n",
    "1.  Query **3-4 representative cities** spread geographically across each bidding zone.\n",
    "2.  Aggregate these forecasts into a single **Zonal Mean**.\n",
    "3.  Map variables to match the ERA5 feature set exactly.\n",
    "4.  **Fallback Strategy:** Since the standard API tier restricts explicit solar radiation data, we estimate it using the UV Index ($Solar \\approx UV \\times 25$) to preserve day/night cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Load Environment Variables\n",
    "env_path = Path('../../secrets.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Retrieve API Key\n",
    "API_KEY = os.getenv('WEATHER_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API Key not found! Please check your secrets.env file.\")\n",
    "\n",
    "print(\"[INFO] Environment loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We define the geographic scope for each zone by selecting representative cities.\n",
    "\n",
    "* **DK1 (West Denmark):** Aarhus, Aalborg, Esbjerg, Odense\n",
    "* **NO2 (South Norway):** Kristiansand, Stavanger, Skien\n",
    "* **ES (Spain):** Madrid, Seville, Bilbao, Barcelona\n",
    "\n",
    "**Output:**\n",
    "Data will be saved to `data/live` in the project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Endpoint\n",
    "BASE_URL = \"http://api.weatherapi.com/v1/forecast.json\"\n",
    "\n",
    "# Output Directory (Project Root / data / live)\n",
    "OUTPUT_DIR = Path('../../data/live')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Representative Cities for Zonal Mean\n",
    "ZONE_LOCATIONS = {\n",
    "    \"DK1\": [\"Aarhus\", \"Aalborg\", \"Esbjerg\", \"Odense\"], \n",
    "    \"NO2\": [\"Kristiansand\", \"Stavanger\", \"Skien\"],     \n",
    "    \"ES\":  [\"Madrid\", \"Seville\", \"Bilbao\", \"Barcelona\"] \n",
    "}\n",
    "\n",
    "print(f\"[INFO] Target Directory: {OUTPUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Function\n",
    "\n",
    "This function queries the API for a specific city.\n",
    "It extracts the exact fields required by our XGBoost model:\n",
    "* `temp_c` -> **temperature_2m**\n",
    "* `precip_mm` -> **precipitation_mm**\n",
    "* `wind_kph` -> **wind_speed_10m** (Requires conversion later)\n",
    "* `short_rad` -> **solar_radiation_W**\n",
    "\n",
    "**Note on Solar Radiation:**\n",
    "If `short_rad` is missing (common in standard API tiers), we use `uv` (UV Index) multiplied by 25.0 as a physical proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_city_forecast(city, days=3):\n",
    "    \"\"\"\n",
    "    Fetches hourly forecast for a specific city.\n",
    "    Returns a DataFrame with raw API columns.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'key': API_KEY,\n",
    "        'q': city,\n",
    "        'days': days,\n",
    "        'aqi': 'no',\n",
    "        'alerts': 'no'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check for API error messages\n",
    "        if 'error' in data:\n",
    "            print(f\"[ERROR] Fetching {city}: {data['error']['message']}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        # Parse Hourly Data\n",
    "        forecast_days = data['forecast']['forecastday']\n",
    "        hourly_list = []\n",
    "        \n",
    "        for day in forecast_days:\n",
    "            for hour in day['hour']:\n",
    "                \n",
    "                # --- SOLAR RADIATION FALLBACK ---\n",
    "                # Try to get explicit Shortwave Radiation\n",
    "                solar_rad = hour.get('short_rad')\n",
    "                \n",
    "                # If missing, approximate using UV Index\n",
    "                # 1 UV Index unit approx 25 W/m2\n",
    "                if solar_rad is None:\n",
    "                    uv_index = hour.get('uv', 0.0)\n",
    "                    solar_rad = uv_index * 25.0\n",
    "                \n",
    "                hourly_list.append({\n",
    "                    'time_local': hour['time'],\n",
    "                    'temperature_2m': hour.get('temp_c'),\n",
    "                    'precipitation_mm': hour.get('precip_mm'),\n",
    "                    'wind_kph': hour.get('wind_kph'),\n",
    "                    'solar_radiation_W': solar_rad\n",
    "                })\n",
    "                \n",
    "        df = pd.DataFrame(hourly_list)\n",
    "        df['time'] = pd.to_datetime(df['time_local'])\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[EXCEPTION] Fetching {city}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zonal Aggregation\n",
    "\n",
    "This main loop iterates through all defined zones. For each zone, it:\n",
    "1.  Fetches forecasts for all defined cities.\n",
    "2.  Aggregates the data by calculating the mean across all cities (Spatial Mean).\n",
    "3.  Converts Wind Speed from `kph` to `m/s` to align with ERA5 training data.\n",
    "4.  Saves the result as a clean CSV for the inference pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_forecasts():\n",
    "    print(\"Starting Forecast Ingestion...\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for zone, cities in ZONE_LOCATIONS.items():\n",
    "        print(f\"Processing Zone: {zone}\")\n",
    "        all_cities_dfs = []\n",
    "        \n",
    "        # 1. Fetch data for each city\n",
    "        for city in cities:\n",
    "            df_city = fetch_city_forecast(city)\n",
    "            if not df_city.empty:\n",
    "                df_city = df_city.set_index('time')\n",
    "                all_cities_dfs.append(df_city)\n",
    "        \n",
    "        if not all_cities_dfs:\n",
    "            print(f\"[SKIP] {zone}: No data fetched.\")\n",
    "            continue\n",
    "            \n",
    "        # 2. Aggregate (Spatial Mean)\n",
    "        # Concatenate all city dataframes\n",
    "        df_combined = pd.concat(all_cities_dfs)\n",
    "        \n",
    "        # Calculate mean, ignoring non-numeric columns (like 'time_local')\n",
    "        df_zonal_mean = df_combined.groupby(df_combined.index).mean(numeric_only=True)\n",
    "        \n",
    "        # 3. Feature Engineering\n",
    "        # Convert Wind Speed: kph -> m/s (1 m/s = 3.6 kph)\n",
    "        if 'wind_kph' in df_zonal_mean.columns:\n",
    "            df_zonal_mean['wind_speed_10m'] = df_zonal_mean['wind_kph'] / 3.6\n",
    "        \n",
    "        # Select and Reorder Final Columns\n",
    "        final_cols = [\n",
    "            'temperature_2m', \n",
    "            'precipitation_mm', \n",
    "            'wind_speed_10m', \n",
    "            'solar_radiation_W'\n",
    "        ]\n",
    "        \n",
    "        # Ensure columns exist (fill 0.0 if missing)\n",
    "        for col in final_cols:\n",
    "            if col not in df_zonal_mean.columns:\n",
    "                df_zonal_mean[col] = 0.0\n",
    "                \n",
    "        df_final = df_zonal_mean[final_cols]\n",
    "        \n",
    "        # 4. Save to CSV\n",
    "        save_path = OUTPUT_DIR / f\"{zone}_forecast.csv\"\n",
    "        df_final.to_csv(save_path)\n",
    "        \n",
    "        print(f\"[SUCCESS] Saved: {save_path.name}\")\n",
    "        print(f\"Time Range: {df_final.index.min()} to {df_final.index.max()}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    process_and_save_forecasts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "\n",
    "We validate the quality of the downloaded data to ensure it is physically realistic before using it for predictions.\n",
    "\n",
    "**Checks:**\n",
    "1.  **Missing Values:** Should be 0.\n",
    "2.  **Physical Ranges:** No negative wind/solar, realistic temperatures.\n",
    "3.  **Visual Check:** Plotting the time series to verify patterns (e.g., daily solar cycles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality():\n",
    "    print(\"\\n--- Running Sanity Checks ---\")\n",
    "    \n",
    "    for zone in ZONE_LOCATIONS.keys():\n",
    "        file_path = OUTPUT_DIR / f\"{zone}_forecast.csv\"\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nZone: {zone}\")\n",
    "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        \n",
    "        # 1. Missing Values\n",
    "        missing = df.isna().sum().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"[WARNING] Found {missing} missing values.\")\n",
    "        else:\n",
    "            print(\"[OK] No missing values.\")\n",
    "            \n",
    "        # 2. Physical Constraints\n",
    "        if df['wind_speed_10m'].min() < 0:\n",
    "            print(\"[CRITICAL] Negative wind speed detected.\")\n",
    "        \n",
    "        if df['solar_radiation_W'].min() < 0:\n",
    "            print(\"[CRITICAL] Negative solar radiation detected.\")\n",
    "            \n",
    "        # 3. Print Stats\n",
    "        print(df.describe().loc[['min', 'max', 'mean']])\n",
    "\n",
    "check_data_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecasts():\n",
    "    for zone in ZONE_LOCATIONS.keys():\n",
    "        file_path = OUTPUT_DIR / f\"{zone}_forecast.csv\"\n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "            \n",
    "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        \n",
    "        # Setup Plot (2 Rows: Temp/Solar and Wind/Precip)\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "        \n",
    "        # Row 1: Temperature & Solar\n",
    "        color_temp = 'tab:red'\n",
    "        ax1.set_ylabel('Temperature (C)', color=color_temp)\n",
    "        ax1.plot(df.index, df['temperature_2m'], color=color_temp, label='Temp')\n",
    "        ax1.tick_params(axis='y', labelcolor=color_temp)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax1_right = ax1.twinx()\n",
    "        color_solar = 'tab:orange'\n",
    "        ax1_right.set_ylabel('Solar (W/m2)', color=color_solar)\n",
    "        ax1_right.plot(df.index, df['solar_radiation_W'], color=color_solar, label='Solar', linestyle='--')\n",
    "        ax1_right.tick_params(axis='y', labelcolor=color_solar)\n",
    "        ax1.set_title(f\"Forecast Validation: {zone}\")\n",
    "        \n",
    "        # Row 2: Wind & Precip\n",
    "        color_wind = 'tab:blue'\n",
    "        ax2.set_ylabel('Wind Speed (m/s)', color=color_wind)\n",
    "        ax2.plot(df.index, df['wind_speed_10m'], color=color_wind, label='Wind')\n",
    "        ax2.tick_params(axis='y', labelcolor=color_wind)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2_right = ax2.twinx()\n",
    "        color_rain = 'tab:cyan'\n",
    "        ax2_right.set_ylabel('Precip (mm)', color=color_rain)\n",
    "        ax2_right.plot(df.index, df['precipitation_mm'], color=color_rain, label='Rain', linestyle=':')\n",
    "        ax2_right.tick_params(axis='y', labelcolor=color_rain)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_forecasts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
